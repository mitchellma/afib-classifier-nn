{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset\n",
    "\n",
    "By using pytorch dataloader, files in dataset are loaded and transformed just in time.  This makes the classifier more memmory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "DATASET_FOLDER = './training/'\n",
    "\n",
    "# timeChannel = 1; time included\n",
    "# dataFormat: 1 = double; 2 = float; 3 = short\n",
    "\n",
    "adibin_header_dtype = np.dtype([('magic', np.string_, 4), \n",
    "                                ('version', np.int32, 1), \n",
    "                                ('secPerTick', np.float64, 1), \n",
    "                                ('year', np.int32, 1), \n",
    "                                ('month', np.int32, 1), \n",
    "                                ('day', np.int32, 1), \n",
    "                                ('hour', np.int32, 1), \n",
    "                                ('min', np.int32, 1), \n",
    "                                ('sec', np.float64, 1), \n",
    "                                ('trigger', np.float64, 1), \n",
    "                                ('numChannels', np.int32, 1), \n",
    "                                ('samplesPerChannel', np.int32, 1), \n",
    "                                ('timeChannel', np.int32, 1), \n",
    "                                ('dataFormat', np.int32, 1)])\n",
    "\n",
    "print(adibin_header_dtype.itemsize)\n",
    "\n",
    "channel_header_dtype = np.dtype([('channelTitle', np.string_, 32), \n",
    "                                 ('units', np.string_, 32), \n",
    "                                 ('scale', np.float64, 1), \n",
    "                                 ('offset', np.float64, 1), \n",
    "                                 ('rangeHight', np.float64, 1),\n",
    "                                 ('rangeLow', np.float64, 1)])\n",
    "\n",
    "print(channel_header_dtype.itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class afibDataset(Dataset):\n",
    "    __xs = []\n",
    "    __ys = []\n",
    "    \n",
    "    def __init__(self, folder_dataset, transform=None):\n",
    "        self.transform = transform\n",
    "        # Open and load text file including the whole training data\n",
    "        with open(folder_dataset + \"data.txt\") as f:\n",
    "            for line in f:\n",
    "                # Image path\n",
    "                self.__xs.append(folder_dataset + line.split()[0])        \n",
    "                # Steering wheel label\n",
    "                self.__ys.append(np.float32(line.split()[1]))\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data = None\n",
    "        \n",
    "        with open(self.__xs[index], 'rb') as file:\n",
    "            \n",
    "            header_buff = file.read(68)\n",
    "            header = np.frombuffer(header_buff, dtype=adibin_header_dtype)\n",
    "            \n",
    "            dataFormat = header[0]['dataFormat']\n",
    "            numChannels = header[0]['numChannels']\n",
    "            \n",
    "            chan_buff = file.read(96*numChannels)\n",
    "            chan_header = np.frombuffer(chan_buff, dtype=channel_header_dtype)\n",
    "\n",
    "            if dataFormat == 1:\n",
    "                frames = np.frombuffer(file.read(), dtype=np.int64)\n",
    "            elif dataFormat == 2:\n",
    "                frames = np.frombuffer(file.read(), dtype=np.int32)\n",
    "            elif dataFormat == 3:\n",
    "                frames = np.frombuffer(file.read(), dtype=np.int16)\n",
    "            else:\n",
    "                print('Invalid channel data format')\n",
    "                return None, None\n",
    "            \n",
    "            deinterleaved = [frames[idx::numChannels] for idx in range(numChannels)]\n",
    "            \n",
    "            print(deinterleaved[0])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        # Convert image and label to torch tensors\n",
    "#         img = torch.from_numpy(np.asarray(img))\n",
    "        label = torch.from_numpy(np.asarray(self.__ys[index]).reshape([1,1]))\n",
    "        return data, label\n",
    "\n",
    "    # Override to give PyTorch size of dataset\n",
    "    def __len__(self):\n",
    "        return len(self.__xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1124306162, -1124523907, -1124775819, ...,  1055355835,\n",
      "        1055314678,  1055272777], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "dataset = afibDataset(DATASET_FOLDER)\n",
    "\n",
    "data = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
